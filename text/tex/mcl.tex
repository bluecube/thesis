\chapter{Monte Carlo Localization}
\label{chap:mcl}

The following chapter defines the localization problem, provides quick overview
of several probabilistic localization algorithms and finally describes
Monte Carlo Localization algorithm.

\section{Localization}
Localization of a mobile robot is a task of estimating position (and possibly
also other state) of the robot based on performed actions and sensor readings.

Localization can mean either position tracking, where the robot knows its initial
position and the task is only to update the estimate and handle relatively small
errors, or global localization, where the robot has to find its position from scratch.

\begin{itemize}
\item ...
\end{itemize}

\section{Markov Localization}

Markov Localization \cite{fox98,diard03} is a recursive probabilistic
algorithm that estimates state of the robot based on its actions and measured sensor data.

\subsection{Derivation}

Markov localization assumes that the state of the robot only depends
on state and action performed in the previous time frame.
%	\begin{equation}
%		\P(X_i = x | X_{1, \dotsc, i - 1}, a_{1, \dotsc, i - 1},
%		o_{1, \dotsc, i - 1}) = 
%		\P(X_i = x | X_{i - 1}, a_{i - 1})
%	\end{equation}
and that each observation only depends on the current state.
%	\begin{equation}
%		\P(o_i | X_1, \dotsc, X_i, a_1, \dotsc, a_{i - 1},
%		o_1, \dotsc, o_{i - 1}) = 
%		\P(o_i | X_i)
%	\end{equation}

It computes probability density of the robot state, called belief.
\begin{equation}
	\label{eq:markov-belief-def}
	\Bel(X_i = x) = \P(X_i = x | o_{1, \dotsc, i}, a_{1,\dotsc,i - 1})
\end{equation}

Here \(X_i\) is the random variable representing robot's state,
\(o_i\) is the observed sensor input in time step \(i\) and \(a_i\)
is the action the robot performs in the time step \(i\), after it
measures \(o_i\).

Using Bayes rule, equation \eqref{eq:markov-belief-def} can be transformed to
\begin{equation}
	\label{eq:markov-derivation1}
	\Bel(X_i = x) =
	\frac{
		\P(o_i | X_i = x, o_{1, \dotsc, i}, a_{1,\dotsc,i - 1})
		\P(X_i = x | o_{1, \dotsc, i}, a_{1, \dotsc, i - 1})
	}{
		\P(o_i | o_{1, \dotsc, i-1}, a_{1, \dotsc, i-1})
	}
\end{equation}

Note that denominator \(\P(o_i | o_{1, \dotsc, i-1}, a_{1, \dotsc, i-1})\) only
serves as a normalization constant.
In further equations it will be replaced by \(\eta^{-1}\).
Other than that, we can use the independence assumptions made at the beginning
of this section and simplify \eqref{eq:markov-derivation1} to

\begin{equation}
	\label{eq:markov-derivation2}
	\Bel(X_i = x) =
		\eta \P(o_i | X_i = x)
		\P(X_i = x | o_{1, \dotsc, i}, a_{1, \dotsc, i - 1})
\end{equation}

%The equation \eqref{eq:markov-derivation1} has already been simplified using
%the independence assumptions.

By integrating over all possible states in time \(i - 1\), the rightmost term in
equation \eqref{eq:markov-derivation1} can be expanded in a following way;

\begin{equation}
	\label{eq:markov-derivation3}
	\P(X_i = x | o_{1, \dotsc, i}, a_{1, \dotsc, i - 1}) = \
	\int
	\P(X_i = x | X_{i - 1}=x', o_{1, \dotsc, i}, a_{1, \dotsc, i - 1})
	\P(X_{i-1} = x' | o_{1, \dotsc, i-1}, a_{1, \dotsc, i-1})
	\mathrm{d}x'
\end{equation}

After substituting definition of belief from equation \eqref{eq:markov-belief-def}
and another use the independence assumptions we get
\begin{equation}
	\label{eq:markov-derivation4}
	\P(X_i = x | o_{1, \dotsc, i}, a_{1, \dotsc, i - 1}) = \
	\int
	\P(X_i = x | X_{i - 1}=x', a_{i - 1})
	\Bel(X_{i-1} = x')
	\mathrm{d}x'
\end{equation}

Finally, substituting into \eqref{eq:markov-derivation2} gives us the recursive
equation

\begin{equation}
	\label{eq:markov-derivation5}
	\Bel(X_i = x) =
	\eta \P(o_i | X_i = x)
		\int
		\P(X_i = x' | a_{i - 1})
		\Bel(X_{i-1} = x')
		\mathrm{d}x'
\end{equation}


We will call the conditional density \(\P(o_i | X_i = x)\) \emph{sensor model} and
the density \(\P(X_i = x' | X_{i - 1}=x', a_{i - 1})\) \emph{motion model}.
Sensor model describes the probability of observing \(o_i\) at given time.
It implicitly contains map of the environment and models interactions of sensors with
the map.
Action model contains information about how the robot's actions relate to changes in its state.





\begin{itemize}
\item Prediction:\\
	Using action model \(P(X_i = x | X_{i-1} = x^\prime, a_{i - 1})\) to predict
	current position based on past state and action
	\begin{equation}
		\label{eq:markov-prediction}
		P(X_i = x | X_{i - 1}, a_{i - 1}) =
		\int
		P(X_i = x | X_{i - 1} = x', a_{i - 1})
		P(X_{i - 1} = x^\prime | o_{i - 1}, a_{i - 2})
		\mathrm{d}x'
	\end{equation}

\item Correction:\\
	Using sensor model \(P(o_i | X_i = x)\) to correct the estimate from prediction phase
	and form a final state estimate for time frame \(i\).
	\begin{equation}
		\label{eq:markov-correction}
		P(X_i = x | X_{i-1}, o_i, a_{i - 1}) =
		\nu P(o_i | X_i = x) P(X_i = x | X_{i - 1}, a_{i - 1})
	\end{equation}
	Note that the denominator in \eqref{eq:markov-correction} is only a normalizer to
	keep probabilities of all positions to sum to \(1\). 
\item Several specialisations of Markov localization exists differing mainly in how the
	current state estimation is represented.
	Examples include Kalman filters, that represent the estimation as Gaussian,
	%(together with other assumptions, see \ref{sec:kalman}),
	grid based algorithms \cite{fox98}, or Monte Carlo localization
	that is described in section \ref{sec:mcl-algorithm}.
\end{itemize}

%\begin{compactitem}
%\item Prediction phase updates the belief from the previous time step based
%on the actions performed by the robot.
%\item Correction phase then updates the belief based on sensor measurements.
%\end{compactitem}


\subsection{Kalman Filters}
\label{sec:kalman}

\begin{itemize}
\item \cite{kalman60,welch95}
\item popular
\item efficient -- mean and covariance matrix is sufficient to store the density.
\item Can be viewed as a closed form solution of Markov localization where both the
	action model and measurement model are linear and Gaussian \cite{diard03}.

	\begin{equation}
	\label{eq:kalman-action-model}
	P(X_i = x | X_{i-1} = x', a_{i - 1}) \sim N(A_{i - 1}x' + B_{i - 1}a_{i - 1}, Q_{i - 1})
	\end{equation}
	\begin{equation}
	\label{eq:kalman-measurement-model}
	P(o_{i} | X_i = x) \sim N(H_{i}x_{i}, R_i)
	\end{equation}
	
	In equations \eqref{eq:kalman-action-model} and \eqref{eq:kalman-measurement-model}
	the matrix \(A_i\) describes change of state if there was no control input and no noise,
	matrix \(B_i\) contains the influence of action \(a_i\) and \(H_i\) relates state to measured
	values.
	\(Q_i\) and \(R_i\) are covariance matrices of action model and measurement model.

\item Non linear motion and measurement models can be approximated 
	using a first order Taylor expansion to form extended Kalman
	filter (EKF) \cite{welch95}.
\end{itemize}

\section{MCL Algorithm}
\label{sec:mcl-algorithm}

\begin{itemize}
\item\cite{dellaert99}
\item Variation of Markov localization that approximates probability densities using
	samples drawn from them.
\item Informally the basic MCL algorithm can be described as follows:
	\begin{compactitem}
	\item Keep \(n\) samples of possible robot states.
	\item Prediction: Move each sample according to the action performed + noise corresponding
		to uncertainty on the action's result (e.g. wheel slip).
	\item Correction: For each sample calculate how probable the incoming measurement is
		in this state and multiply sample's weight by this probability.
	\item Resampling: Throw away samples with low weights, and instead add copies of the
		highly weighted samples.
	\end{compactitem}

\item Uses a set of samples \(S_i = \{s^k_{i} | k = 1,\dotsc,n\} \) drawn from
	\(P(X_i = x | X_{i-1}, o_i, a_{i - 1})\) to represent the belief.

\item Prediction:\\
	\emph{
	Draw a new sample \(s'^k_{i}\)
	from the action model \(P(X_i = x | X_{i-1} = s^k_{i-1}, a_{i - 1})\)
	for every sample in \(S_{i-1}\).
	}

	The resulting set \(S'_i = \{s'^k_{i}\} \) is sampled from
	density defined in equation \eqref{eq:mcl-predictive-density} and approximates the predictive
	density from \eqref{eq:markov-prediction}
	
	\begin{equation}
		\label{eq:mcl-predictive-density}
		\hat{P}(X_i = x | X_{i - 1}, a_{i - 1}) =
		\sum_{k = 1}^n P(X_i = x | X_{i-1} = s^k_{i-1}, a_{i - 1})
	\end{equation}

\item Correction:\\
	\emph{
	Use the sensor model to calculate weight \(w^k_i = P(o_i | X_i = s'^k_i)\)
	for each sample in \(S'_i\).
	}

	Ideally, the correction phase would draw samples directly from
	\(P(o_i | X_i = x) P(X_i = x | X_{i - 1}, a_{i - 1})\),
	however there is no easy way to achieve this.
	Instead, Monte Carlo localization 
	uses SIR (sampling / importance resampling, \cite{smith92})
	to generate samples drawn from
	\(P(o_i | X_i = x) \hat{P}(X_i = x | X_{i - 1}, a_{i - 1})\) from the set \(S'_i\).
	This is achieved by weighting the samples as described earlier and resampling
	according to these weights in the next phase.

%	\begin{equation}
%		w^k_i = 
%		\frac{
%			P(o_i | X_i = s'^k_i) \hat{P}(X_i = s'^k_i | X_{i - 1}, a_{i - 1})
%		}{
%			\hat{P}(X_i =  s'^k_i | X_{i - 1}, a_{i - 1})
%		} = P(o_i | X_i = s'^k_i)
%	\end{equation}


\item Resampling:\\
	\emph{
	Draw \(n\) new samples \(s^k_{i+1}\) from \(S_i\) by placing
	weight \(\{w^k_i\}\) on \(s^k_{i}\)
	}
\end{itemize}
